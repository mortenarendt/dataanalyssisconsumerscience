
# Liking scores

[INTRO NEEDED]

Liking scores is often 1-5, 1-7 or 1-9 [more Bom?]

Most often we want to know if the liking scored significantly different (not just different by chance) depending on the samples. We might also wna to know if other factors have an influence on the liking. e.g. household income. We also want to know what are the actual differences are. 


## Plotting liking scores

For the beer data we have the liking in a long matrix. We need to import the data: 

```{r}
library(readxl)
beerliking <- read_excel('DatasetRbook.xlsx',sheet = 'BeerLiking')
```


[MORTEN: meget simpel kode til fx histogram med sprednigner på - gennemsnit per øl og et plot, der viser fordeling af scores. Altså om de evt. er skævt fordelt per øl. Det kan man ikke se af et gennemsit...]



## Simple mixed models

Mixed models are used when there is repetitions in the response due to (here) the person tasting more than one product.

[MERE TEKST PÅ HER]
[Forklar fixed og random effects? Måske bruge dette:Fixed effects are effects that we anticipate have the same direction, e.g., mutual differences between products. Would typically be the same from one experiment to another as the products are unchanging entities. Random effects are effects that we cannot predict, e.g., mutual differences between consumers may differ from one experiment to another as consumers are affected by various emotional, environmental, physiological or other influences in their lives]

```{r}
library(lmerTest)
mdl <- lmer(data = beerliking, Liking ~ Beer + (1|Consumer.ID)) 
anova(mdl)
```

[MORTEN: Sensorikere er virkelig glade for p-værdier for en variabel - det kan jeg ikke se, jeg kan få ud med lme4, derfor foreslår jeg  pakken lmerTest i stedet for. Lavet af Per Brockhoff til sensorikdata. og så også anova() i stedet for summary(). Så kommer der een overordnet p-værdi ud ]

To explain the model: take the dataset called _beerliking_ and calculate a model where _Beer_ is the fixed effect and the consumer is the random effect for the response variable _Liking_. Use the function _lmer_ and save the output as _mdl_. The anova() function will provide you with the p value(s). Remember you choose your own title of your model. 

[MANGLER: forklaring på output; At least two of the products by name are scored significantly different for the liking.]



### Post hoc contrasts

[HEDDER DET DET? korrekt titel?]
[SKAL SKRIVES DET HELE]

To calculate pairwise comparisons between e.g. samples and find letter-based representation you need a the package _multcomp_. 

```{r}
library(multcomp)
cld(glht(mdl, linfct = mcp(Beer = "Tukey")))
```

[MANGLER: forklaring på model og output]

The letters are based on the Post Hoc test Tukey, and they are calculated on the basis of the model _mdl_. Samples with the same letters are not significantly different. You can only use this function on factors. 

[MORTEN: Hvis man nu har kontinuerte variable, hvordan fortolkes det så?]



## Multiway mixed models

[explain + output + interpret]

In multiway models, we start with the largest possible, i.e., including all relevant explanatory variables (e.g., including the product variable). We then have to eliminate non-significant variables manually one by one (backwards step-wise elimination). The final model will only contain the significant variables.

In the beer dataset it could be nice to calculate if the liking is affected by the gender and age of the consumer. 

```{r}
library(lmerTest)
mdl.2 <- lmer(data = beerliking, Liking ~ Beer + Gender + Age + (1|Consumer.ID)) 
summary(mdl.2)
```

[MANGLER: FORTOLKNING AF  OUTPUT]


It could be  ice to calculate if the liking of specific sample are affected by the age, so we include the interaction between _Beer_ and _Age_:

```{r}
mdl.3 <- lmer(data = beerliking, Liking ~ Beer + Beer*Age + (1|Consumer.ID)) 
summary(mdl.2)
```

Remember you choose your own “name” for the model
“+” between variables defines (additive) main effects
“:”  between variables defines an interaction
“*” between variables defines a parameterization with both interaction and main effect terms

For model selection here, you start by removing the interaction with the hight p-value and then recalculate the model. You cannot remove a single variable if an interaction including it is significant. 

[MANGLER: FORTOLKNING AF  OUTPUT]
