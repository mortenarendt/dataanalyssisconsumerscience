[["index.html", "Data Analysis in R for Consumer Science Chapter 1 Introduction", " Data Analysis in R for Consumer Science Morten Arendt Rasmussens 2022-08-12 Chapter 1 Introduction This material is to cover data analysis using R for consumer science targeting the courses: Meal systems technology Food consumer research Meal consumer research Thematic course in food innovation Public health nutrition But others may benefit from the material as well…. "],["data.html", "Chapter 2 Data 2.1 Read in data from Excel - iBuffet", " Chapter 2 Data In this book several datasets are used targeting different research questions. However, a fair part of the analysis tools are common. That is, descriptive analysis, plots, response correlations etc. The data is included in the R-packgage you get by running the code below. Be aware that you need devtools package to install from github. # install data-package install.packages(&#39;devtools&#39;) devtools::install_github(&#39;mortenarendt/data4consumerscience&#39;) The data is also available as excel sheets, and can be loaded using packages capable of reading from excel. Below is an example using data from the so-called iBuffet 2.1 Read in data from Excel - iBuffet The data from the iBuffet comes in the form of csv or excel files. These can be in the form of Consumption data from the Buffet Survey data on liking, motivation, choices etc attaced to the particular buffet Survey data on demographics for the participants such as age, gender, eating habits etc. These are general and different from the former, in that they have nothing to do with the current buffet. Example of Buffet data 2.1.1 Example of Survey data Example of Survey data 2.1.2 Example of Survey Scale Survey Scale used 2.1.3 Edit in excel Turn the files into sheets in excel having all in one file. Setup the data in excel such that they match the above in terms of format. What is important is: First row is used on headings and none of these are repeated. I.e. all unique within a sheet Data comes from row 2. All rows should contain data (empty cell as also data), so all empty rows are removed Headings between sheets refering to the same: e.g. participant ID should have exactly similar heading. If you have calculated stuff within excel such as a sum of the numbers in a coloum, then these should be removed from the sheet. It is not data! We suggest that you keep both the original version of the data as a sheet, and the ready-to-import as a sheet. 2.1.4 Importing to R Each of the sheets are imported seperately. Here we use the package readxl with the function read_excel. If the data is not in the same folder as your script, then include the path to the data, or move the data to the location. Be aware that the SurveyScale sheet does not have a heading. Here we import without (col_names = F), and set it manually afterwards, but you can also put it in manually. library(readxl) Buffet &lt;- read_excel(&#39;./data/iBuffet.xlsx&#39;,sheet = &#39;BuffetData&#39;) Survey &lt;- read_excel(&#39;./data/iBuffet.xlsx&#39;,sheet = &#39;SurveyData&#39;) Surveyscales &lt;- read_excel(&#39;./data/iBuffet.xlsx&#39;, sheet = &#39;SurveyScale&#39;, col_names = F) ## New names: ## • `` -&gt; `...1` ## • `` -&gt; `...2` colnames(Surveyscales) &lt;- c(&#39;answ&#39;,&#39;number&#39;) Have a look at the imported elements to ensure that indeed, they mimic the excel-sheets. head(), str() and View() is your tools. head(Buffet) ## # A tibble: 6 × 4 ## Person Day StationName Consumption ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 P01 1 Pasta with legumes 90 ## 2 P01 1 Pasta with mushroom 148 ## 3 P02 1 Pasta with legumes 172 ## 4 P02 1 Pasta with mushroom 40 ## 5 P03 1 Pasta with legumes 56 ## 6 P03 1 Pasta with mushroom 52 str(Buffet) ## tibble [60 × 4] (S3: tbl_df/tbl/data.frame) ## $ Person : chr [1:60] &quot;P01&quot; &quot;P01&quot; &quot;P02&quot; &quot;P02&quot; ... ## $ Day : num [1:60] 1 1 1 1 1 1 1 1 1 1 ... ## $ StationName: chr [1:60] &quot;Pasta with legumes&quot; &quot;Pasta with mushroom&quot; &quot;Pasta with legumes&quot; &quot;Pasta with mushroom&quot; ... ## $ Consumption: num [1:60] 90 148 172 40 56 52 66 86 304 336 ... We see that the coloum with names (Person and StationName) is interpreted as characters (chr) while the stuff which should be numbers (Comsuption) is numeric (num). If that is not the case, you will need to transform them using as.numeric() or as.character(). 2.1.5 Editing in R The Buffet data is optimal as is. We have the data as long format with all repsonse in one coloumn and then coloums clearifying the design, time, type, person etc. However the Survey data is not optimal directly. Things to fix: * The 7-point for the last four questions we want en encode as a numerical factor correctly leveled. * The data can additionally be versioned in both long and wide format library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() Surveylong &lt;- Survey %&gt;% gather(question,answ, `Pasta with legumes is visually appealing to me. `: `I like the taste of pasta with mushrooms! `) %&gt;% mutate(answ = answ %&gt;% factor(levels = Surveyscales$answ), answnum = answ %&gt;% as.numeric()) Surveywide &lt;- Surveylong %&gt;% select(-answ) %&gt;% spread(question,answnum) 2.1.6 Merging the data For the sake of being able to compare consumption (obtained from buffet data) with liking and motives (obtained from the survey data) these data frames needs to be merged. There are several merge options, here we use left_join() but full_join() and right_join() might more suited in some situations. 2.1.6.1 Adding survey to buffets Merging should be done such that Person and Day match. If you additionally have demographic data (gender, age, etc.) then obviously only Person should match, as the data is constant over Days. Buffet_survey &lt;- Buffet %&gt;% left_join(Surveywide, by = c(&#39;Person&#39;,&#39;Day&#39;)) 2.1.6.2 Adding buffet to survey Similarly, merging should be done such that Person and Day match. If you additionally have demographic data (gender, age, etc.) then obviously only Person should match, as the data is constant over Days. Further, we use the long format of the survey data here. Surveylong_buffet &lt;- Surveylong %&gt;% left_join(Buffet, by = c(&#39;Person&#39;,&#39;Day&#39;)) Due to not having a total overlap of information, some responses (here for consumption) will be missing. That you can see using the table function. table(is.na(Surveylong_buffet$Consumption)) ## ## FALSE ## 240 2.1.7 Save the data You can export any data frame from R to excel (for instance using the rio package), as well as saving it as .RData for further analysis. Use save.image() to save everything, or use save() to specify which elements to save save.image(file = &#39;iBuffetSurveyDataEverything.RData&#39;) # everything save(file = &#39;iBuffetSurveyData.RData&#39;, list = c(&#39;Survey&#39;,&#39;Surveylong_buffet&#39;, &#39;Surveylong&#39;,&#39;Buffet_survey&#39;,&#39;Surveyscales&#39;)) # just the usesul and non-redundant stuff. rio::export(Surveylong_buffet,file = &#39;Surveylong_buffet.xlsx&#39;) # export one data frame 2.1.8 Ready for analysis Now you can simply load the data directly, and do not need to do the import-setup every time you want to do an analysis on the data. This part is not a part of the data import, but it is a good idea just to check that the data indeed is setup as expected. load(&#39;iBuffetSurveyData.RData&#39;) "],["libraries.html", "Chapter 3 Libraries", " Chapter 3 Libraries R comes with a bit of functionality. However, most of the useful tools in R is distributed as packages. There are +10.000 package for R, so it is a jungle to figure out what the most easy solution to your problem at hand is. However, the teams who have made tidyverse and ggplot2 etc. have made a lot of things much more easy, and we strongly rely on their tools and routines in data analysis. To install packages from CRAN (the main repo where R-packages are distributed) install.packages(&#39;somepackage&#39;) To install packages from github (the place where all the development and general code sharing is distributed) devtools::install_github(&#39;developername/packagename&#39;) To make packages available within your analysis use library(), or use the package name followed by :: and the function library(ggplot2) # lets plot dadta library(tidyverse) library(ggpubr) # lets add stats to the plots library(knitr) # lets make nice tables ggplot2::qplot(rnorm(100)) # example of a function call without library&#39;ing the package. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. "],["descriptive-statistics-and-plotting.html", "Chapter 4 Descriptive statistics and plotting 4.1 Distributions of count data 4.2 Scatter plots", " Chapter 4 Descriptive statistics and plotting load(&#39;iBuffetSurveyData.RData&#39;) 4.1 Distributions of count data The table function is good in getting how many observations there are within a given vector, or combinations of several vectors. Here used on the Survey answers. table(Surveylong$answ) # across everything ## ## A. Strongly disagree B. Disagree ## 0 2 ## C. More or less disagree D. Neither agree nor disagree ## 6 7 ## E. More or less agree F. Agree ## 21 32 ## G. Strongly agree ## 52 table(Surveylong$question,Surveylong$answ ) # across question ## ## A. Strongly disagree ## I like the taste of pasta with legumes!  0 ## I like the taste of pasta with mushrooms!  0 ## Pasta with legumes is visually appealing to me.  0 ## Pasta with mushrooms is visually appealing to me.  0 ## ## B. Disagree ## I like the taste of pasta with legumes!  1 ## I like the taste of pasta with mushrooms!  0 ## Pasta with legumes is visually appealing to me.  1 ## Pasta with mushrooms is visually appealing to me.  0 ## ## C. More or less disagree ## I like the taste of pasta with legumes!  3 ## I like the taste of pasta with mushrooms!  0 ## Pasta with legumes is visually appealing to me.  3 ## Pasta with mushrooms is visually appealing to me.  0 ## ## D. Neither agree nor disagree ## I like the taste of pasta with legumes!  2 ## I like the taste of pasta with mushrooms!  0 ## Pasta with legumes is visually appealing to me.  3 ## Pasta with mushrooms is visually appealing to me.  2 ## ## E. More or less agree ## I like the taste of pasta with legumes!  5 ## I like the taste of pasta with mushrooms!  4 ## Pasta with legumes is visually appealing to me.  6 ## Pasta with mushrooms is visually appealing to me.  6 ## ## F. Agree G. Strongly agree ## I like the taste of pasta with legumes!  8 11 ## I like the taste of pasta with mushrooms!  11 15 ## Pasta with legumes is visually appealing to me.  7 10 ## Pasta with mushrooms is visually appealing to me.  6 16 You see that most of the answers are in agreement with question, and that there are no observations in the Strongly disagree category. The tidyverse way Lets do exactly the same just using tidyverse functions count(), group_by(), mutate(), and summarise(). Further, lets print the results in a nice looking table using kable() from the knitr package. # tb &lt;- Surveylong %&gt;% # count(question,answ,Day,name = &quot;no_rows&quot;, .drop = F) # kable(tb, caption = &#39;some caption&#39;) The numbers are absolute, but may be better represented by proportions. tb &lt;- Surveylong %&gt;% group_by(question,Day) %&gt;% dplyr::mutate(ntot = n()) %&gt;% group_by(question,answ,Day) %&gt;% dplyr::summarise(n = n(), prc = 100*n / ntot[1]) ## `summarise()` has grouped output by &#39;question&#39;, &#39;answ&#39;. You can override using ## the `.groups` argument. kable(tb, caption = &#39;some caption&#39;, digits = 1) Table 4.1: some caption question answ Day n prc I like the taste of pasta with legumes!  B. Disagree 1 1 6.7 I like the taste of pasta with legumes!  C. More or less disagree 2 3 20.0 I like the taste of pasta with legumes!  D. Neither agree nor disagree 1 1 6.7 I like the taste of pasta with legumes!  D. Neither agree nor disagree 2 1 6.7 I like the taste of pasta with legumes!  E. More or less agree 1 4 26.7 I like the taste of pasta with legumes!  E. More or less agree 2 1 6.7 I like the taste of pasta with legumes!  F. Agree 1 3 20.0 I like the taste of pasta with legumes!  F. Agree 2 5 33.3 I like the taste of pasta with legumes!  G. Strongly agree 1 6 40.0 I like the taste of pasta with legumes!  G. Strongly agree 2 5 33.3 I like the taste of pasta with mushrooms!  E. More or less agree 1 2 13.3 I like the taste of pasta with mushrooms!  E. More or less agree 2 2 13.3 I like the taste of pasta with mushrooms!  F. Agree 1 5 33.3 I like the taste of pasta with mushrooms!  F. Agree 2 6 40.0 I like the taste of pasta with mushrooms!  G. Strongly agree 1 8 53.3 I like the taste of pasta with mushrooms!  G. Strongly agree 2 7 46.7 Pasta with legumes is visually appealing to me.  B. Disagree 1 1 6.7 Pasta with legumes is visually appealing to me.  C. More or less disagree 1 1 6.7 Pasta with legumes is visually appealing to me.  C. More or less disagree 2 2 13.3 Pasta with legumes is visually appealing to me.  D. Neither agree nor disagree 1 2 13.3 Pasta with legumes is visually appealing to me.  D. Neither agree nor disagree 2 1 6.7 Pasta with legumes is visually appealing to me.  E. More or less agree 1 1 6.7 Pasta with legumes is visually appealing to me.  E. More or less agree 2 5 33.3 Pasta with legumes is visually appealing to me.  F. Agree 1 5 33.3 Pasta with legumes is visually appealing to me.  F. Agree 2 2 13.3 Pasta with legumes is visually appealing to me.  G. Strongly agree 1 5 33.3 Pasta with legumes is visually appealing to me.  G. Strongly agree 2 5 33.3 Pasta with mushrooms is visually appealing to me.  D. Neither agree nor disagree 1 1 6.7 Pasta with mushrooms is visually appealing to me.  D. Neither agree nor disagree 2 1 6.7 Pasta with mushrooms is visually appealing to me.  E. More or less agree 1 3 20.0 Pasta with mushrooms is visually appealing to me.  E. More or less agree 2 3 20.0 Pasta with mushrooms is visually appealing to me.  F. Agree 2 6 40.0 Pasta with mushrooms is visually appealing to me.  G. Strongly agree 1 11 73.3 Pasta with mushrooms is visually appealing to me.  G. Strongly agree 2 5 33.3 … and a plot of it tb %&gt;% ggplot(data = ., aes(answ,prc, fill = factor(Day))) + geom_bar(stat = &#39;identity&#39;, position = position_dodge()) + facet_wrap(~question) + theme(axis.text.x = element_text(angle = 45,hjust = 1), legend.position = &#39;top&#39;) 4.1.1 Descriptives for a continouos variable Here just across the entire sample set. mean(Buffet_survey$Consumption) ## [1] 138 median(Buffet_survey$Consumption) ## [1] 126 sd(Buffet_survey$Consumption) ## [1] 85.45472 IQR(Buffet_survey$Consumption) ## [1] 112.5 summary(Buffet_survey$Consumption) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 74.0 126.0 138.0 186.5 378.0 This is a very high level representation, and we usually want to compare means (or other metrics) between different groups. We use the consumption and split it according to day and pasta-type. tb2 &lt;- Buffet_survey %&gt;% group_by(StationName, Day) %&gt;% dplyr::summarise(nobs = n(), mean = mean(Consumption), median = median(Consumption), sd = sd(Consumption), iqr = IQR(Consumption), q25 = quantile(Consumption,0.25), q75 = quantile(Consumption,0.75)) ## `summarise()` has grouped output by &#39;StationName&#39;. You can override using the ## `.groups` argument. kable(tb2, digits = 1, caption = &#39;some relevant caption&#39;) Table 4.2: some relevant caption StationName Day nobs mean median sd iqr q25 q75 Pasta with legumes 1 15 132.3 130 81.2 101 71 172 Pasta with legumes 2 15 155.7 138 103.7 139 71 210 Pasta with mushroom 1 15 135.1 92 88.7 99 76 175 Pasta with mushroom 2 15 128.9 124 71.3 85 86 171 Corresponding plot of data Buffet_survey %&gt;% ggplot(data = ., aes(StationName,Consumption, fill = factor(Day))) + geom_violin() Buffet_survey %&gt;% ggplot(data = ., aes(StationName,Consumption, fill = factor(Day))) + geom_boxplot() + geom_jitter() Corresponding plots of the results ggplot(data= tb2, aes(factor(StationName):factor(Day),mean, color = factor(Day), ymin = mean-sd, ymax = mean + sd)) + geom_point() + geom_errorbar(width = 0.3)+ theme(axis.text.x = element_text(angle = 45,hjust = 1)) + ylab(&#39;mean+/- 1*sd&#39;) 4.1.1.1 In relation to protein considerations Try to make these descriptive analysis and plots taking into account whether the participants considered protein content, and why they did. Here is some inspiration. Buffet_survey %&gt;% ggplot(data = ., aes(`Did you consider the protein content of the dish(es) you chose?`, Consumption)) + geom_boxplot() + geom_jitter() + facet_wrap(~StationName) 4.2 Scatter plots Lets plot the consumption as a function of the answers to the liking-scale questions of the survey, and split it into day and type of vegetable. If you think about it, it is pretty many plots, but the ggplot2 functionality facet_wrap() on a long format data frame does it in few lines: Surveylong_buffet %&gt;% filter(!is.na(StationName )) %&gt;% mutate(question2 = question %&gt;% substr(1,34)) %&gt;% # The label is to long, so lets just represent the first 30 letters. ggplot(data = ., aes(answnum,Consumption, color = factor(Day))) + geom_point() + stat_smooth(se = F, method = lm) + stat_cor() + facet_grid(question2 ~ StationName) + theme_bw() + theme(legend.position = &#39;bottom&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; kable(Surveyscales, caption = &#39;Just a table to have what the 7point likert scale numbers mean&#39;) Table 4.3: Just a table to have what the 7point likert scale numbers mean answ number A. Strongly disagree 1 B. Disagree 2 C. More or less disagree 3 D. Neither agree nor disagree 4 E. More or less agree 5 F. Agree 6 G. Strongly agree 7 Get this stuff to work, and try to interpret what you see: which factors seems important for the portion size ( Consumption )? The summary-stats in the scatter plots above: What is this? How is it interpreted? test4 "],["pca-on-survey-answers.html", "Chapter 5 PCA on survey answers 5.1 Bi-plot", " Chapter 5 PCA on survey answers knitr::include_url(&quot;https://youtube.com/embed/NFIkD9-MuTY&quot;) We use a package called ggbiplot for plotting the PCA model. It is located on github and installed by: install.packages(&#39;devtools&#39;) devtools::install_github(&#39;vqv/ggbiplot&#39;) library(ggplot2) # lets plot dadta library(tidyverse) library(broom) library(broom.mixed) library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack library(ggbiplot) ## Loading required package: plyr ## ------------------------------------------------------------------------------ ## You have loaded plyr after dplyr - this is likely to cause problems. ## If you need functions from both plyr and dplyr, please load plyr first, then dplyr: ## library(plyr); library(dplyr) ## ------------------------------------------------------------------------------ ## ## Attaching package: &#39;plyr&#39; ## The following object is masked from &#39;package:ggpubr&#39;: ## ## mutate ## The following objects are masked from &#39;package:dplyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following object is masked from &#39;package:purrr&#39;: ## ## compact ## Loading required package: scales ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor ## Loading required package: grid library(ggpubr) # lets add stats to the plots library(knitr) # lets make nice tables library(data4consumerscience) PCA is a tool for looking a correlation structure between variabels, and groupings of samples. All through visualizations. Check out youtube on the subject for an introduction. PCA takes numerical data as input, so we use the likert-scales in the form of 1 to 7. Further the yes/no answers are included, and also needs to be changed. x &lt;- pasta %&gt;% mutate(Did_you_take_food_from_both_Dish1_and_Dish2 = Did_you_take_food_from_both_Dish1_and_Dish2 %&gt;% factor %&gt;% as.numeric(), Did_you_consider_the_proteincontent_of_the_dishes_you_choose = Did_you_consider_the_proteincontent_of_the_dishes_you_choose %&gt;% factor() %&gt;% as.numeric()) %&gt;% mutate_if(is.factor, as.numeric) %&gt;% filter(Day==1) %&gt;% # the survey part is the same for both days and both stations. That is what we keep. filter(str_detect(StationName,&#39;leg&#39;)) PCAmdl &lt;- prcomp(x[,c(5:6,8:11)],scale. = T) 5.1 Bi-plot And a plot of the model ggbiplot(PCAmdl, varname.size = 5) + ylim(c(-4,4)) + xlim(c(-2,5)) What does component 1 (PC1) reflect? What does PC2 reflect? Lets plot the model and color the samples according to the consumption (of legumes) cutted at the median. ggbiplot(PCAmdl, groups = factor(x$Consumption&gt;130), ellipse = T, varname.size = 5) + ylim(c(-4,4)) + xlim(c(-3,5)) 5.1.1 Extract the components and run all associations. We are interested in if any of the likert/survey traits reflected by PCA is correlated with consumption. It is a little complicated, but here goes scores &lt;- data.frame(Person = x$Person, PCAmdl$x[,1:2]) # take out the first two components. tbmixed &lt;- pasta %&gt;% left_join(scores, by = &#39;Person&#39;) %&gt;% gather(comp,score,PC1:PC2) %&gt;% group_by(StationName,comp) %&gt;% do(lmer(data = ., Consumption~score + Day + (1|Person)) %&gt;% tidy(conf.int = T)) … Make a table and a plot of the results. tbmixed %&gt;% filter(term==&#39;score&#39;) %&gt;% select(-effect,-group) %&gt;% kable(x = .,caption = &#39;Slopes according to components&#39;, digits = 2) Table 5.1: Slopes according to components StationName comp term estimate std.error statistic conf.low conf.high Pasta with legumes PC1 score 14.28 13.26 1.08 -11.70 40.27 Pasta with legumes PC2 score -19.47 17.80 -1.09 -54.34 15.41 Pasta with mushroom PC1 score 5.15 10.69 0.48 -15.80 26.11 Pasta with mushroom PC2 score -4.93 14.43 -0.34 -33.21 23.35 tbmixed %&gt;% filter(term==&#39;score&#39;) %&gt;% ggplot(data = ., aes(comp,estimate,ymin = conf.low, ymax = conf.high)) + geom_errorbar(width = 0.1) +geom_point()+ geom_hline(yintercept = 0) + facet_grid(~StationName) + theme(legend.position = &#39;bottom&#39;) Interpret the results. "],["linear-models.html", "Chapter 6 Linear models 6.1 Example 6.2 Run a bunch of models at once", " Chapter 6 Linear models Linear models is a general term for models with a single univariate response (dependent variable - \\(y\\) in the formula below), which we want to describe using one or several predictors (independent variables - \\(x\\) in the formula below). \\[ y = a + b \\cdot x + e \\] Here the informative parameter is the slope (\\(b\\)) which indicates the relation between \\(x\\) and \\(y\\). (\\(e\\) is the missfit / residuals of the model). We use tidyverse coding as this makes life much easier. As an tidyverse add on, we use broom for the linear models, broom.mixed and lme4 for the linear mixed models. library(ggplot2) # lets plot dadta library(tidyverse) library(broom) library(broom.mixed) library(lme4) library(ggpubr) # lets add stats to the plots library(knitr) # lets make nice tables The data is already imported, and formated (see Getting_data_in.pdf for details). We simply load this file. library(data4consumerscience) 6.1 Example As response variable, the amount of Consumption of Pasta with mushrooms and use the likert scale I like the taste of pasta with mushrooms! as predictor. We use ONLY Day 1 results. First a plot: pasta %&gt;% filter(str_detect(StationName,&#39;mush&#39;)) %&gt;% filter(Day==1) %&gt;% ggplot(data = ., aes(I_like_taste_of_pasta_with_mushrooms,Consumption)) + geom_point() + stat_smooth(method = lm, se = F) ## `geom_smooth()` using formula &#39;y ~ x&#39; It seems as there is something. So lets build a linear model on this # subset the data x &lt;- pasta %&gt;% filter(str_detect(StationName,&#39;mush&#39;)) %&gt;% filter(Day==1) mdl &lt;- lm(data = x, Consumption~I_like_taste_of_pasta_with_mushrooms) mdl ## ## Call: ## lm(formula = Consumption ~ I_like_taste_of_pasta_with_mushrooms, ## data = x) ## ## Coefficients: ## (Intercept) ## 89.00 ## I_like_taste_of_pasta_with_mushroomsAgree ## 6.60 ## I_like_taste_of_pasta_with_mushroomsStrongly agree ## 82.25 summary(mdl) ## ## Call: ## lm(formula = Consumption ~ I_like_taste_of_pasta_with_mushrooms, ## data = x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -119.25 -49.60 -3.00 35.58 164.75 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 89.00 60.43 1.473 ## I_like_taste_of_pasta_with_mushroomsAgree 6.60 71.50 0.092 ## I_like_taste_of_pasta_with_mushroomsStrongly agree 82.25 67.56 1.217 ## Pr(&gt;|t|) ## (Intercept) 0.167 ## I_like_taste_of_pasta_with_mushroomsAgree 0.928 ## I_like_taste_of_pasta_with_mushroomsStrongly agree 0.247 ## ## Residual standard error: 85.46 on 12 degrees of freedom ## Multiple R-squared: 0.2043, Adjusted R-squared: 0.07173 ## F-statistic: 1.541 on 2 and 12 DF, p-value: 0.2537 The the slope indicates that by increasing liking by one unit the consumption increase is \\(50.2 \\pm 30.4\\), however, this apparent effect is not statistically significant (\\(p = 0.12\\)). 6.2 Run a bunch of models at once We want to model consumption of both pasta with mushrooms andd legumes, and look at all the likert scales questions as predictors. Further we want to do this for both days. First we create a new long format data frame pastalong &lt;- pasta %&gt;% gather(question,answ,I_like_taste_of_pasta_with_legumes:Pasta_with_mushrooms_is_visually_appealing) %&gt;% mutate(answnum = factor(answ,labels = c(&#39;Disagree&#39;,&#39;More or less disagree&#39;,&#39;Neither agree nor disagree&#39;,&#39;More or less agree&#39;,&#39;Agree&#39;,&#39;Strongly agree&#39;)) %&gt;% as.numeric()) ## Warning: attributes are not identical across measure variables; ## they will be dropped 6.2.1 A plot pastalong %&gt;% filter(!is.na(StationName )) %&gt;% mutate(question2 = question %&gt;% substr(1,34)) %&gt;% # The label is to long, so lets just represent the first 30 letters. ggplot(data = ., aes(answnum,Consumption, color = factor(Day))) + geom_point() + stat_smooth(se = F, method = lm) + stat_cor() + facet_grid(question2 ~ StationName) + theme_bw() + theme(legend.position = &#39;bottom&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; This we similary can run as several linear models. tb &lt;- pastalong %&gt;% filter(!is.na(StationName )) %&gt;% group_by(StationName,question,Day) %&gt;% do(lm(data = ., Consumption~answnum) %&gt;% tidy(conf.int = T)) tb %&gt;% filter(term==&#39;answnum&#39;) %&gt;% select(-statistic) %&gt;% kable(x = .,caption = &#39;All linear models&#39;, digits = 2) Table 6.1: All linear models StationName question Day term estimate std.error p.value conf.low conf.high Pasta with legumes I_like_taste_of_pasta_with_legumes 1 answnum 8.51 10.65 0.44 -14.49 31.51 Pasta with legumes I_like_taste_of_pasta_with_legumes 2 answnum -4.24 13.27 0.75 -32.91 24.42 Pasta with legumes I_like_taste_of_pasta_with_mushrooms 1 answnum 1.93 9.47 0.84 -18.53 22.39 Pasta with legumes I_like_taste_of_pasta_with_mushrooms 2 answnum 15.10 11.16 0.20 -9.00 39.21 Pasta with legumes Pasta_with_legumes_is_visually_appealing 1 answnum 23.36 7.75 0.01 6.61 40.10 Pasta with legumes Pasta_with_legumes_is_visually_appealing 2 answnum 8.50 16.06 0.61 -26.19 43.19 Pasta with legumes Pasta_with_mushrooms_is_visually_appealing 1 answnum 11.75 17.95 0.52 -27.04 50.54 Pasta with legumes Pasta_with_mushrooms_is_visually_appealing 2 answnum 13.17 12.21 0.30 -13.21 39.55 Pasta with mushroom I_like_taste_of_pasta_with_legumes 1 answnum -10.34 11.56 0.39 -35.32 14.63 Pasta with mushroom I_like_taste_of_pasta_with_legumes 2 answnum 4.33 9.07 0.64 -15.27 23.93 Pasta with mushroom I_like_taste_of_pasta_with_mushrooms 1 answnum 16.00 9.36 0.11 -4.22 36.23 Pasta with mushroom I_like_taste_of_pasta_with_mushrooms 2 answnum 3.75 8.12 0.65 -13.80 21.29 Pasta with mushroom Pasta_with_legumes_is_visually_appealing 1 answnum 8.89 10.75 0.42 -14.35 32.12 Pasta with mushroom Pasta_with_legumes_is_visually_appealing 2 answnum -13.86 10.47 0.21 -36.48 8.75 Pasta with mushroom Pasta_with_mushrooms_is_visually_appealing 1 answnum 16.81 19.38 0.40 -25.05 58.67 Pasta with mushroom Pasta_with_mushrooms_is_visually_appealing 2 answnum -10.72 8.24 0.22 -28.52 7.08 .. A plot of these results for a quick interpretation. tb %&gt;% filter(term==&#39;answnum&#39;) %&gt;% ggplot(data = ., aes(question,estimate,ymin = conf.low, ymax = conf.high, color = factor(Day))) + geom_errorbar(width = 0.1, position = position_dodge()) +geom_point()+ geom_hline(yintercept = 0) + coord_flip() +facet_grid(~StationName) + theme(legend.position = &#39;bottom&#39;) Seems as some of the legume consumptions there is a significant association with likert scales. Not as strong for consumption of mushrooms. "],["mixed-models.html", "Chapter 7 Mixed models 7.1 With several variables", " Chapter 7 Mixed models Mixed models are used when there is repetitions in the response due to (here) the person conducting the trial. The two days are repetitions, and hence we can use all the data (not splitting in to days), but need to account for the person in the model. # subset the data x &lt;- pasta %&gt;% filter(str_detect(StationName,&#39;mush&#39;)) mdl &lt;- lmer(data = x, Consumption~I_like_taste_of_pasta_with_mushrooms + Day + (1|Person)) summary(mdl) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Consumption ~ I_like_taste_of_pasta_with_mushrooms + Day + (1 | ## Person) ## Data: x ## ## REML criterion at convergence: 309 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.1229 -0.5717 -0.1507 0.4085 2.0757 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Person (Intercept) 1561 39.51 ## Residual 4794 69.24 ## Number of obs: 30, groups: Person, 15 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 112.594 56.211 2.003 ## I_like_taste_of_pasta_with_mushroomsAgree -1.222 47.725 -0.026 ## I_like_taste_of_pasta_with_mushroomsStrongly agree 48.220 46.189 1.044 ## Day -2.837 25.380 -0.112 ## ## Correlation of Fixed Effects: ## (Intr) I_____ I____a ## I_lk_t____A -0.595 ## I_lk_____Sa -0.662 0.748 ## Day -0.678 -0.035 0.028 This is the joint effect between the two days. Think of an average of the two slopes - one for each day -. Here taking into account that each person has provided two responses of the consumption of pasta with mushrooms. This can also be accomplised using the tidyverse setup engined by the broom.mixed package. In principle, we simply do not loop over Day, but include it in the formula along with person. tbmixed &lt;- pastalong %&gt;% filter(!is.na(StationName )) %&gt;% group_by(StationName,question) %&gt;% do(lmer(data = ., Consumption~answnum + Day + (1|Person)) %&gt;% tidy(conf.int = T)) The output here is a bit different than the lm() model. But it is still the slope of answnum which carries the interesting stuff. tbmixed %&gt;% filter(term==&#39;answnum&#39;) %&gt;% select(-effect,-group) %&gt;% kable(x = .,caption = &#39;All mixed linear models&#39;, digits = 2) Table 7.1: All mixed linear models StationName question term estimate std.error statistic conf.low conf.high Pasta with legumes I_like_taste_of_pasta_with_legumes answnum 1.71 7.86 0.22 -13.71 17.12 Pasta with legumes I_like_taste_of_pasta_with_mushrooms answnum 6.12 7.65 0.80 -8.87 21.11 Pasta with legumes Pasta_with_legumes_is_visually_appealing answnum 14.16 8.17 1.73 -1.86 30.18 Pasta with legumes Pasta_with_mushrooms_is_visually_appealing answnum 6.23 8.83 0.71 -11.08 23.53 Pasta with mushroom I_like_taste_of_pasta_with_legumes answnum -2.12 7.36 -0.29 -16.56 12.31 Pasta with mushroom I_like_taste_of_pasta_with_mushrooms answnum 10.25 6.53 1.57 -2.55 23.05 Pasta with mushroom Pasta_with_legumes_is_visually_appealing answnum -4.21 7.87 -0.54 -19.63 11.20 Pasta with mushroom Pasta_with_mushrooms_is_visually_appealing answnum -4.33 8.38 -0.52 -20.76 12.10 tbmixed %&gt;% filter(term==&#39;answnum&#39;) %&gt;% ggplot(data = ., aes(question,estimate,ymin = conf.low, ymax = conf.high)) + geom_errorbar(width = 0.1) +geom_point()+ geom_hline(yintercept = 0) + coord_flip() +facet_grid(~StationName) + theme(legend.position = &#39;bottom&#39;) Do the associations match as expected? 7.1 With several variables We can add several predictors to the model, here that could several likert-scale questions, and maybe demographics with the consumption as response. This is in principle the same for both linear models and linear mixed models. x &lt;- pasta %&gt;% filter(str_detect(StationName,&#39;mush&#39;)) mdl &lt;- lmer(data = x, Consumption~I_like_taste_of_pasta_with_mushrooms + Pasta_with_mushrooms_is_visually_appealing + Day + (1|Person)) summary(mdl) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## Consumption ~ I_like_taste_of_pasta_with_mushrooms + Pasta_with_mushrooms_is_visually_appealing + ## Day + (1 | Person) ## Data: x ## ## REML criterion at convergence: 278.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.0180 -0.6058 -0.2061 0.3717 1.9421 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Person (Intercept) 1602 40.03 ## Residual 5399 73.48 ## Number of obs: 30, groups: Person, 15 ## ## Fixed effects: ## Estimate ## (Intercept) 106.913 ## I_like_taste_of_pasta_with_mushroomsAgree 9.942 ## I_like_taste_of_pasta_with_mushroomsStrongly agree 62.756 ## Pasta_with_mushrooms_is_visually_appealingMore or less agree 26.432 ## Pasta_with_mushrooms_is_visually_appealingAgree 23.132 ## Pasta_with_mushrooms_is_visually_appealingStrongly agree -1.810 ## Day -12.589 ## Std. Error t value ## (Intercept) 86.627 1.234 ## I_like_taste_of_pasta_with_mushroomsAgree 59.439 0.167 ## I_like_taste_of_pasta_with_mushroomsStrongly agree 70.044 0.896 ## Pasta_with_mushrooms_is_visually_appealingMore or less agree 74.905 0.353 ## Pasta_with_mushrooms_is_visually_appealingAgree 85.788 0.270 ## Pasta_with_mushrooms_is_visually_appealingStrongly agree 79.813 -0.023 ## Day 32.740 -0.385 ## ## Correlation of Fixed Effects: ## (Intr) I_____ I____a P__ola P_____ P____a ## I_lk_t____A -0.325 ## I_lk_____Sa -0.307 0.824 ## Ps_____Mola -0.659 0.001 -0.005 ## Pst_wt____A -0.331 -0.313 -0.452 0.682 ## Pst_w____Sa -0.531 -0.365 -0.486 0.726 0.849 ## Day -0.556 -0.032 0.044 -0.008 -0.247 0.061 mdl %&gt;% tidy(conf.int = T) ## # A tibble: 9 × 8 ## effect group term estim…¹ std.e…² stati…³ conf.…⁴ conf.…⁵ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed &lt;NA&gt; (Intercept) 107. 86.6 1.23 -62.9 277. ## 2 fixed &lt;NA&gt; I_like_taste_of_pas… 9.94 59.4 0.167 -107. 126. ## 3 fixed &lt;NA&gt; I_like_taste_of_pas… 62.8 70.0 0.896 -74.5 200. ## 4 fixed &lt;NA&gt; Pasta_with_mushroom… 26.4 74.9 0.353 -120. 173. ## 5 fixed &lt;NA&gt; Pasta_with_mushroom… 23.1 85.8 0.270 -145. 191. ## 6 fixed &lt;NA&gt; Pasta_with_mushroom… -1.81 79.8 -0.0227 -158. 155. ## 7 fixed &lt;NA&gt; Day -12.6 32.7 -0.385 -76.8 51.6 ## 8 ran_pars Person sd__(Intercept) 40.0 NA NA NA NA ## 9 ran_pars Residual sd__Observation 73.5 NA NA NA NA ## # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, ## # ⁴​conf.low, ⁵​conf.high Try to interpret the slopes? Are the slopes significantly different from 0 (i.e. the point of no association). .. And hey! Why is the slope for visual all of a sudden negative?… Does that mean that consumption increase the less you like the visual appearance? .. Or what? Complete the same analysis with legumes. "],["check-all-that-applies-cata.html", "Chapter 8 Check All That Applies (CATA) 8.1 An example from Beer profiling 8.2 Two versions of the data 8.3 PCA 8.4 Cochranes Q-test", " Chapter 8 Check All That Applies (CATA) Check All That Apply (CATA) data is in its raw form binary indicating whether a judge finds a product to have the attribute (1) or not (0). Usually, such data is organized in a matrix where each row corresponds to the evaluation of one product by one judge. And the coloumns are then the attributes. Say you for instance have 26 judges/consummers and 4 products, and further that all products are evaluated by all judges once on 13 attributes. Your data matrix would then have 104 rows and 13 coloums (with responses) and additionally coloumns indicating judge, product, record id, date, etc. 8.1 An example from Beer profiling library(data4consumerscience) library(tidyverse) data(&quot;beercata&quot;) beercata %&gt;% head() ## Consumer.ID Beer S_Flowers S_Beans S_Intense berries S_Caramel S_Nuts ## 1 a01 Wheat IPA 0 0 0 0 1 ## 2 a02 Wheat IPA 0 0 0 0 0 ## 3 a03 Wheat IPA 0 0 0 0 0 ## 4 a04 Wheat IPA 0 1 0 0 0 ## 5 a05 Wheat IPA 0 0 0 0 0 ## 6 a06 Wheat IPA 0 0 0 0 0 ## S_Savoury spices S_Dessert spices S_Regional spices S_Herbs S_Citrus fruit ## 1 0 0 0 1 0 ## 2 0 0 1 0 0 ## 3 0 0 0 0 0 ## 4 1 0 0 0 0 ## 5 0 0 0 0 1 ## 6 0 0 0 1 0 ## S_Berries S_Fruit S_Dried fruit S_Liquor S_Bitter S_Sparkling S_Refreshing ## 1 0 0 0 0 1 0 0 ## 2 0 0 0 0 0 0 0 ## 3 1 0 0 0 1 0 0 ## 4 0 0 0 0 1 0 1 ## 5 0 0 0 0 1 0 1 ## 6 0 0 1 0 1 1 0 ## S_Fruity S_Aromatic S_Pungent S_Still S_Smoked S_Foamy S_Sour S_Sweet ## 1 0 1 1 0 0 0 0 0 ## 2 0 0 0 0 0 0 1 0 ## 3 0 0 0 0 1 1 0 0 ## 4 0 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 0 0 0 ## 6 0 0 0 0 1 0 0 0 ## S_Warming S_Vinous ## 1 0 0 ## 2 0 0 ## 3 0 0 ## 4 0 0 ## 5 0 0 ## 6 0 0 table(beercata$Beer) ## ## Brown Ale NY Lager Porse Bock Ravnsborg Red River Beer ## 160 160 160 160 160 ## Wheat IPA ## 160 length(unique(beercata$Consumer.ID)) ## [1] 160 8.2 Two versions of the data RAW data with each row being responses from one evaluation Agglomerated to counts, with each row being one product The agglomerated version is computed by: # Questions we want answer using these data # - Are the products different / similar? # - Which attributes drives discrimination? # - Are there any judges who are really of? beercatasum &lt;- beercata %&gt;% gather(attrib, val, S_Flowers:S_Vinous) %&gt;% group_by(Beer,attrib) %&gt;% dplyr::summarize(n = sum(val)) %&gt;% spread(attrib,n) ## `summarise()` has grouped output by &#39;Beer&#39;. You can override using the ## `.groups` argument. beercatasum ## # A tibble: 6 × 28 ## # Groups: Beer [6] ## Beer S_Aro…¹ S_Beans S_Ber…² S_Bit…³ S_Car…⁴ S_Cit…⁵ S_Des…⁶ S_Dri…⁷ S_Flo…⁸ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Brown… 57 54 6 63 52 10 13 21 4 ## 2 NY La… 37 10 5 69 16 30 20 6 46 ## 3 Porse… 20 2 5 67 7 34 16 6 27 ## 4 Ravns… 52 25 6 71 35 11 19 14 17 ## 5 River… 22 12 4 65 3 29 8 4 22 ## 6 Wheat… 29 9 9 57 9 30 24 6 45 ## # … with 18 more variables: S_Foamy &lt;dbl&gt;, S_Fruit &lt;dbl&gt;, S_Fruity &lt;dbl&gt;, ## # S_Herbs &lt;dbl&gt;, `S_Intense berries` &lt;dbl&gt;, S_Liquor &lt;dbl&gt;, S_Nuts &lt;dbl&gt;, ## # S_Pungent &lt;dbl&gt;, S_Refreshing &lt;dbl&gt;, `S_Regional spices` &lt;dbl&gt;, ## # `S_Savoury spices` &lt;dbl&gt;, S_Smoked &lt;dbl&gt;, S_Sour &lt;dbl&gt;, S_Sparkling &lt;dbl&gt;, ## # S_Still &lt;dbl&gt;, S_Sweet &lt;dbl&gt;, S_Vinous &lt;dbl&gt;, S_Warming &lt;dbl&gt;, and ## # abbreviated variable names ¹​S_Aromatic, ²​S_Berries, ³​S_Bitter, ⁴​S_Caramel, ## # ⁵​`S_Citrus fruit`, ⁶​`S_Dessert spices`, ⁷​`S_Dried fruit`, ⁸​S_Flowers ## # ℹ Use `colnames()` to see all variable names … and visualized by for instance a barplot. # summary counts over attrobite beercatasum %&gt;% gather(attrib, n, S_Flowers:S_Vinous) %&gt;% ggplot(data = ., aes(attrib,n, fill = Beer)) + geom_bar(stat = &#39;identity&#39;, position = position_dodge()) + coord_flip() 8.3 PCA A PCA on the agglomerated counts, reveal the attributes associated with the individual products: mdlPCA &lt;- prcomp(beercatasum[,-1], scale. = T) ggbiplot::ggbiplot(mdlPCA, labels = beercatasum$Beer) The attributes Bean, Caramel, Warming, Aromatic etc is associated to the beer Brown ale, while Berrie, Dessert, Pungent, etc. is characteristic of Wheat IPA [Maybe add some more narrative] 8.4 Cochranes Q-test Cochranes Q-test is a statistical test for the comparison of several products, where the response is binary, and there is repeated responses across several judges. We need a package (RVAideeeeMemoire). For one response variable: S_Flowers library(RVAideMemoire) ## *** Package RVAideMemoire v 0.9-81-2 *** ## ## Attaching package: &#39;RVAideMemoire&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## dummy ## The following object is masked from &#39;package:broom&#39;: ## ## bootstrap m &lt;- cochran.qtest(S_Flowers ~ Beer | Consumer.ID, data = beercata) m ## ## Cochran&#39;s Q test ## ## data: S_Flowers by Beer, block = Consumer.ID ## Q = 63.252, df = 5, p-value = 2.581e-12 ## alternative hypothesis: true difference in probabilities is not equal to 0 ## sample estimates: ## proba in group &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 0.02500 0.28750 0.16875 0.10625 0.13750 ## &lt;NA&gt; ## 0.28125 The p.value is strongly significant, indicating that we cannot assumme the same level of S_Flower in all beers. I.e. the beers seems different based on this characteristics. This is in agreement with the barplot above, where S_Flower is high in NY Lager and really low for Brown ale. 8.4.1 Post hoc contrasts As we observe differences based on this attribute, we pursue the question on which products sticks out? And are there products which are similar? This is done by pairwise comparisons: library(rcompanion) PT = pairwiseMcnemar(S_Flowers ~ Beer | Consumer.ID, data = beercata, test = &quot;permutation&quot;, method = &quot;fdr&quot;, digits = 3) PT$Pairwise %&gt;% arrange(-abs(as.numeric(Z))) %&gt;% data.frame() ## Comparison Z p.value p.adjust ## 1 Brown Ale - NY Lager = 0 -6.48 9.13e-11 1.37e-09 ## 2 Brown Ale - Wheat IPA = 0 -5.86 4.71e-09 3.53e-08 ## 3 Brown Ale - Porse Bock = 0 -4.27 1.95e-05 9.75e-05 ## 4 NY Lager - Ravnsborg Red = 0 4.14 3.43e-05 1.29e-04 ## 5 Ravnsborg Red - Wheat IPA = 0 -3.96 7.5e-05 2.25e-04 ## 6 NY Lager - River Beer = 0 3.54 0.000402 8.48e-04 ## 7 Brown Ale - River Beer = 0 -3.53 0.000415 8.48e-04 ## 8 River Beer - Wheat IPA = 0 -3.51 0.000452 8.48e-04 ## 9 Brown Ale - Ravnsborg Red = 0 -2.98 0.00286 4.77e-03 ## 10 NY Lager - Porse Bock = 0 2.52 0.0118 1.77e-02 ## 11 Porse Bock - Wheat IPA = 0 -2.36 0.0181 2.47e-02 ## 12 Porse Bock - Ravnsborg Red = 0 1.54 0.123 1.54e-01 ## 13 Porse Bock - River Beer = 0 0.845 0.398 4.26e-01 ## 14 Ravnsborg Red - River Beer = 0 -0.845 0.398 4.26e-01 ## 15 NY Lager - Wheat IPA = 0 0.135 0.893 8.93e-01 The table is sorted with the most different pairs at the top, and the least different at the bottom. Hence most products are different, while Porse Bock and Ravnsborg Red are fairly alike. 8.4.2 For all Attributes We use tidyverse and broom for this, but need a function capable of handling Cochranes Q-test outputs. library(broom) tidy.RVtest &lt;- function(m){ r &lt;- data.frame(statistic = m$statistic,df = m$parameter, p.value= m$p.value, method = m$method.test) return(r) } tb_cochran &lt;- beercata %&gt;% gather(attrib, val, S_Flowers:S_Vinous) %&gt;% group_by(attrib) %&gt;% do(cochran.qtest(val ~ Beer | Consumer.ID, data = .) %&gt;% tidy) tb_cochran %&gt;% arrange(p.value) ## # A tibble: 27 × 5 ## # Groups: attrib [27] ## attrib statistic df p.value method ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 S_Beans 114. 5 7.19e-23 Cochran&#39;s Q test ## 2 S_Caramel 108. 5 1.08e-21 Cochran&#39;s Q test ## 3 S_Flowers 63.3 5 2.58e-12 Cochran&#39;s Q test ## 4 S_Aromatic 45.8 5 9.90e- 9 Cochran&#39;s Q test ## 5 S_Sweet 36.3 5 8.24e- 7 Cochran&#39;s Q test ## 6 S_Warming 35.9 5 1.01e- 6 Cochran&#39;s Q test ## 7 S_Smoked 33.9 5 2.47e- 6 Cochran&#39;s Q test ## 8 S_Liquor 33.9 5 2.55e- 6 Cochran&#39;s Q test ## 9 S_Citrus fruit 29.4 5 1.96e- 5 Cochran&#39;s Q test ## 10 S_Dried fruit 26.0 5 8.81e- 5 Cochran&#39;s Q test ## # … with 17 more rows ## # ℹ Use `print(n = ...)` to see more rows This output indicates that S_Beans is the most discriminatory attribute, while S_Pungent is the least. 8.4.3 PLSDA This needs more love. library(caret) ## Loading required package: lattice ## ## Attaching package: &#39;caret&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## lift mdl &lt;- plsda(data.frame(beercata[,3:29]),factor(beercata$Beer),ncomp = 3) scores &lt;- mdl$scores %&gt;% unclass %&gt;% as.data.frame %&gt;% cbind(beercata) loadings &lt;- mdl$loadings %&gt;% unclass %&gt;% as.data.frame %&gt;% rownames_to_column(&#39;attrib&#39;) %&gt;% mutate(attrib2 = substr(attrib,3,50)) # lets remove the S_ g1 &lt;- ggplot(data = loadings, aes(`Comp 1`, `Comp 2`, label = attrib2)) + # geom_point() + geom_text() g2 &lt;- ggplot(data = scores, aes(`Comp 1`, `Comp 2`, color = Beer)) + # geom_point() + stat_ellipse(level = 0.5) library(patchwork) g1 + g2 # do multiple splithalfs # INPUT: judge id. CATA, class, ncomp X &lt;- beercata[,3:29] clss &lt;- factor(beercata$Beer) judge &lt;- beercata$Consumer.ID k &lt;- 3 A &lt;- 30 mdl0 &lt;- plsda(X,clss,ncomp = k) lds0 &lt;- mdl0$loadings %&gt;% unclass %&gt;% as.data.frame %&gt;% rownames_to_column(&#39;attrib&#39;) %&gt;% gather(cmp,val0,-attrib) unjudge &lt;- unique(judge) nindiv &lt;- length(unjudge) LOADS &lt;- data.frame() for (i in 1:A){ ic &lt;- judge %in% sample(unjudge)[1:round(nindiv/2)] mdlSH &lt;- plsda(X[ic,],clss[ic],ncomp = k) df_flip &lt;- data.frame(sng = sign(diag(t(mdl0$loadings) %*% mdlSH$loadings))) %&gt;% rownames_to_column(&#39;cmp&#39;) lds &lt;- mdlSH$loadings %&gt;% unclass %&gt;% as.data.frame %&gt;% rownames_to_column(&#39;attrib&#39;) %&gt;% gather(cmp,val,-attrib) %&gt;% left_join(df_flip, by = &#39;cmp&#39;) %&gt;% mutate(SHiter = i, val = val*sng) LOADS &lt;- bind_rows(LOADS,lds) } fc &lt;- (1 / A)*((A - 1)/A) sdloads &lt;- LOADS %&gt;% left_join(lds0, by = c(&#39;attrib&#39;,&#39;cmp&#39;)) %&gt;% group_by(attrib,cmp) %&gt;% dplyr::summarise(sd = sum((val-val0)^2) *fc) %&gt;% mutate(cmp = paste(&#39;sd&#39;,cmp,sep = &#39;&#39;)) %&gt;% spread(cmp,sd) ## `summarise()` has grouped output by &#39;attrib&#39;. You can override using the ## `.groups` argument. loadsSH &lt;- lds0 %&gt;% spread(cmp,val0) %&gt;% left_join(sdloads, by = &#39;attrib&#39;) library(ggforce) ggplot(data = loadsSH, aes(x0 = `Comp 1`,y0 = `Comp 2`,a = `sdComp 1`,b = `sdComp 2`,angle = 0)) + geom_ellipse() "],["consumer-segmentation.html", "Chapter 9 Consumer Segmentation 9.1 Kmeans", " Chapter 9 Consumer Segmentation 9.1 Kmeans "],["more-pca.html", "Chapter 10 More PCA", " Chapter 10 More PCA "],["pls-for-product-profiling.html", "Chapter 11 PLS for product profiling", " Chapter 11 PLS for product profiling "],["logistic-regression.html", "Chapter 12 Logistic Regression", " Chapter 12 Logistic Regression "],["confirmatory-factor-analysis-using-lavaan.html", "Chapter 13 Confirmatory Factor Analysis using lavaan 13.1 Example - Food Neophobia", " Chapter 13 Confirmatory Factor Analysis using lavaan 13.1 Example - Food Neophobia "],["structured-equation-modelling.html", "Chapter 14 Structured Equation Modelling 14.1 Example - Theory of Planned Behaviour", " Chapter 14 Structured Equation Modelling 14.1 Example - Theory of Planned Behaviour 2+2 ## [1] 4 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
